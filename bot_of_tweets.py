# -*- coding: utf-8 -*-
"""BOT OF TWEETS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QaP4zJ0yF14FlYN5XGVPvoJO6aSA1X9B
"""

# Load tweets dataset
df = pd.read_csv('/content/training.1600000.processed.noemoticon.csv', encoding='latin-1', names=['target', 'ids', 'date', 'flag', 'user', 'text'])

# Keep relevant columns
df = df[['target', 'text']]

# Map sentiments
label_map = {0: 'negative', 4: 'positive'}
df['sentiment'] = df['target'].map(label_map)

# Keep only positive and negative
df = df[df['sentiment'].isin(['positive', 'negative'])].copy()

# Binary labels
df['sentiment_binary'] = df['sentiment'].map({'negative': 0, 'positive': 1})

df.head()

"""**1.Importing Libraries**"""

import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import random

"""**2.Data Cleaning**"""

def clean_text(text):
    text = re.sub(r'http\S+', '', text)  # Remove URLs
    text = re.sub(r'@\w+', '', text)     # Remove mentions
    text = re.sub(r'#\w+', '', text)     # Remove hashtags
    text = re.sub(r'[^A-Za-z\s]', '', text)  # Remove special characters
    text = text.lower().strip()
    text = re.sub(r'\s+', ' ', text)
    return text

df['cleaned_text'] = df['text'].apply(clean_text)
df[['text', 'cleaned_text']].head()

"""**3.TRAIN-TEST-SPLIT**"""

X = df['cleaned_text']
y = df['sentiment_binary']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

"""**4.TF-IDF Vectorization**"""

tfidf = TfidfVectorizer(stop_words='english', max_features=5000)

X_train_vec = tfidf.fit_transform(X_train)
X_test_vec = tfidf.transform(X_test)

"""**5.Logistic Regression Model**"""

model = LogisticRegression(max_iter=200)
model.fit(X_train_vec, y_train)

"""**7.Model Evaluation**"""

y_pred = model.predict(X_test_vec)
print(f"Accuracy: {accuracy_score(y_test, y_pred):.2f}")
print(classification_report(y_test, y_pred))

cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Negative', 'Positive'], yticklabels=['Negative', 'Positive'])
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""**8.Bot Reply Check**"""

# Sarcasm keyword approx ‚Äî basic for demo
sarcasm_keywords = ['yeah right', 'sure', 'obviously', 'great job', 'as if']

def detect_sarcasm(text):
    for word in sarcasm_keywords:
        if word in text.lower():
            return True
    return False

def bot_reply(text):
    cleaned = clean_text(text)

    # Detect sarcasm
    if detect_sarcasm(cleaned):
        return "We sense some sarcasm there üòâ Appreciate the feedback!"

    vec = tfidf.transform([cleaned])
    pred = model.predict(vec)[0]

    if pred == 1:
        positive_replies = [
            "Thank you so much for the support! üéâ",
            "We appreciate your positivity! üòä",
            "Glad you enjoyed it, stay tuned! üöÄ"
        ]
        return random.choice(positive_replies)

    else:
        negative_actions = [
            "Sorry to hear that, we'll try to improve.",
            "We respect your feedback. Thanks for sharing.",
            "Appreciate your honesty, working to be better."
        ]
        return random.choice(negative_actions)

"""**9.Testing Tweets**"""

sample_tweets = [
    "Absolutely love your content, keep shining!",
    "Yeah right, that feature works sooo well üòí",
    "Terrible service, really disappointed.",
    "Best video I‚Äôve seen today!",
    "As if this update solved anything!"
]

for tweet in sample_tweets:
    reply = bot_reply(tweet)
    print(f"Incoming Tweet: {tweet}\nBot Action: {reply}\n")

import matplotlib.pyplot as plt

# Pie Chart for Sentiment Distribution
sentiment_counts = df['sentiment'].value_counts()

plt.figure(figsize=(6,6))
colors = ['#ff9999','#66b3ff']
plt.pie(sentiment_counts, labels=sentiment_counts.index, colors=colors, autopct='%1.1f%%', startangle=140)
plt.title('Sentiment Distribution of Tweets')
plt.show()

def advanced_sarcasm_detector(text):
    sarcasm_signals = [
        'yeah right', 'as if', 'obviously', 'totally works',
        'sure that helped', 'works sooo well', 'love that bug'
    ]
    text_lower = text.lower()
    return any(phrase in text_lower for phrase in sarcasm_signals)

"""***SPAM TEXT MANAGEMENT***"""

spam_keywords = ['follow me', 'buy now', 'discount', 'click link', 'subscribe', 'check profile']

def detect_spam(text):
    text_lower = text.lower()
    return any(word in text_lower for word in spam_keywords)

"""*GOOD WISHES*"""

celebration_keywords = ['happy birthday', 'congrats', 'congratulations', 'good luck', 'best wishes', 'happy new year']

def detect_celebration(text):
    text_lower = text.lower()
    return any(word in text_lower for word in celebration_keywords)

def smart_reply(text):
    cleaned = clean_text(text)

    if detect_spam(cleaned):
        return "Detected promotional content, no reply needed."

    if advanced_sarcasm_detector(cleaned):
        return "Sensed sarcasm üòè Thanks for the 'feedback'!"

    if detect_celebration(cleaned):
        return random.choice(["Thank you for the wishes! üéâ", "Appreciate the greetings! üôè", "Sending good vibes back! üåü"])

    vec = tfidf.transform([cleaned])
    pred = model.predict(vec)[0]

    if pred == 1:
        return random.choice(["Thank you so much! üéâ", "Appreciate the love! üíñ", "Stay awesome! üöÄ"])
    else:
        return random.choice(["We value your honesty!", "Noted! We'll improve.", "Thanks for your feedback."])

sample_tweets = [
    "Absolutely love your content, keep shining!",
    "Yeah right, that feature works sooo well üòí",
    "Terrible service, really disappointed.",
    "Best video I‚Äôve seen today!",
    "As if this update solved anything!",
    "Happy birthday bro, have a blast!",
    "Buy now, 50% discount on all items!"
]

for tweet in sample_tweets:
    print(f"Tweet: {tweet}")
    print(f"Bot Reply: {smart_reply(tweet)}")
    print("-" * 50)

from google.colab import drive
drive.mount('/content/drive')

import streamlit as st

st.title("Tweet Sentiment Analyzer & Auto-Reply Bot")

tweet = st.text_input("Enter Tweet Text:")

if st.button("Analyze & Reply"):
    reply = smart_reply(tweet)
    st.success(f"Bot Reply: {reply}")

